#-------------------------------------
# Q&A Server address (for client)
SERVER_URL="127.0.0.1"
SERVER_PORT="8000"

#-------------------------------------
# Cache for models
CACHE_DIR='./cache'

#-------------------------------------
# ServiceMesh MD document directory
DOCUMENT_DIR="source_data"

#-------------------------------------
# Vector store settings
VECTOR_DB_DIR="./.vectorstore"

#-------------------------------------
# OpenVINO Settings
MODEL_PRECISION="INT8"          # "FP16", "INT8", "INT4"
INFERENCE_DEVICE="CPU"          # "CPU", "GPU", "GPU.0" (iGPU), "GPU.1" (dGPU)

#-------------------------------------
# LLM Model settings
MODEL_VENDOR="hfl"
MODEL_NAME="llama-3-chinese-8b-instruct-v3"

#MODEL_VENDOR="Intel"
#MODEL_NAME="neural-chat-7b-v3-1"

#MODEL_VENDOR="databricks"
#MODEL_NAME="dolly-v2-3b"

#-------------------------------------
# Text embeddings model 
# (the default model for langchain.embeddings.HuggingFaceEmbeddings is all-mpnet-base-v2)
MODEL_EMBEDDINGS = 'jinaai/jina-embeddings-v2-base-zh'

#-------------------------------------
# RAG Generation/Pipeline settings
NUM_MAX_TOKENS=512
RAG_CHAIN_TYPE="stuff"      # "stuff", "map_reduce", "map_rerank", "refine"

HUGGINGFACE_TOKEN="THE HUGGINGFACE TOKEN VALUE"
